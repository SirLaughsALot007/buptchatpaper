\begin{thebibliography}{10}

\bibitem{wang2017tacotron}
Yuxuan Wang, RJ~Skerry-Ryan, Daisy Stanton, Yonghui Wu, Ron~J Weiss, Navdeep
  Jaitly, Zongheng Yang, Ying Xiao, Zhifeng Chen, Samy Bengio, et~al.,
\newblock ``Tacotron: Towards end-to-end speech synthesis,''
\newblock {\em arXiv preprint arXiv:1703.10135}, 2017.

\bibitem{arik2017deep}
Sercan~{\"O} Ar{\i}k, Mike Chrzanowski, Adam Coates, Gregory Diamos, Andrew
  Gibiansky, Yongguo Kang, Xian Li, John Miller, Andrew Ng, Jonathan Raiman,
  et~al.,
\newblock ``Deep voice: Real-time neural text-to-speech,''
\newblock in {\em International Conference on Machine Learning}. PMLR, 2017,
  pp. 195--204.

\bibitem{li2019neural}
Naihan Li, Shujie Liu, Yanqing Liu, Sheng Zhao, and Ming Liu,
\newblock ``Neural speech synthesis with transformer network,''
\newblock in {\em Proceedings of the AAAI Conference on Artificial
  Intelligence}, 2019, vol.~33, pp. 6706--6713.

\bibitem{ren2019fastspeech}
Yi~Ren, Yangjun Ruan, Xu~Tan, Tao Qin, Sheng Zhao, Zhou Zhao, and Tie-Yan Liu,
\newblock ``Fastspeech: Fast, robust and controllable text to speech,''
\newblock {\em Advances in Neural Information Processing Systems}, vol. 32,
  2019.

\bibitem{kim2020glow}
Jaehyeon Kim, Sungwon Kim, Jungil Kong, and Sungroh Yoon,
\newblock ``Glow-tts: A generative flow for text-to-speech via monotonic
  alignment search,''
\newblock {\em Advances in Neural Information Processing Systems}, vol. 33, pp.
  8067--8077, 2020.

\bibitem{elias2021parallel}
Isaac Elias, Heiga Zen, Jonathan Shen, Yu~Zhang, Ye~Jia, Ron~J Weiss, and
  Yonghui Wu,
\newblock ``Parallel tacotron: Non-autoregressive and controllable tts,''
\newblock in {\em ICASSP 2021-2021 IEEE International Conference on Acoustics,
  Speech and Signal Processing (ICASSP)}. IEEE, 2021, pp. 5709--5713.

\bibitem{radford2018improving}
Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever, et~al.,
\newblock ``Improving language understanding by generative pre-training,''
\newblock 2018.

\bibitem{brown2020language}
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared~D Kaplan, Prafulla
  Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell,
  et~al.,
\newblock ``Language models are few-shot learners,''
\newblock {\em Advances in neural information processing systems}, vol. 33, pp.
  1877--1901, 2020.

\bibitem{borsos2022audiolm}
Zal{\'a}n Borsos, Rapha{\"e}l Marinier, Damien Vincent, Eugene Kharitonov,
  Olivier Pietquin, Matt Sharifi, Olivier Teboul, David Grangier, Marco
  Tagliasacchi, and Neil Zeghidour,
\newblock ``Audiolm: a language modeling approach to audio generation,''
\newblock {\em arXiv preprint arXiv:2209.03143}, 2022.

\bibitem{wang2023neural}
Chengyi Wang, Sanyuan Chen, Yu~Wu, Ziqiang Zhang, Long Zhou, Shujie Liu, Zhuo
  Chen, Yanqing Liu, Huaming Wang, Jinyu Li, et~al.,
\newblock ``Neural codec language models are zero-shot text to speech
  synthesizers,''
\newblock {\em arXiv preprint arXiv:2301.02111}, 2023.

\bibitem{zhang2023speak}
Ziqiang Zhang, Long Zhou, Chengyi Wang, Sanyuan Chen, Yu~Wu, Shujie Liu, Zhuo
  Chen, Yanqing Liu, Huaming Wang, Jinyu Li, et~al.,
\newblock ``Speak foreign languages with your own voice: Cross-lingual neural
  codec language modeling,''
\newblock {\em arXiv preprint arXiv:2303.03926}, 2023.

\bibitem{kharitonov2023speak}
Eugene Kharitonov, Damien Vincent, Zal{\'a}n Borsos, Rapha{\"e}l Marinier,
  Sertan Girgin, Olivier Pietquin, Matt Sharifi, Marco Tagliasacchi, and Neil
  Zeghidour,
\newblock ``Speak, read and prompt: High-fidelity text-to-speech with minimal
  supervision,''
\newblock {\em arXiv preprint arXiv:2302.03540}, 2023.

\bibitem{levkovitch2022zero}
Alon Levkovitch, Eliya Nachmani, and Lior Wolf,
\newblock ``Zero-shot voice conditioning for denoising diffusion tts models,''
\newblock {\em arXiv preprint arXiv:2206.02246}, 2022.

\bibitem{shen2023naturalspeech}
Kai Shen, Zeqian Ju, Xu~Tan, Yanqing Liu, Yichong Leng, Lei He, Tao Qin, Sheng
  Zhao, and Jiang Bian,
\newblock ``Naturalspeech 2: Latent diffusion models are natural and zero-shot
  speech and singing synthesizers,''
\newblock {\em arXiv preprint arXiv:2304.09116}, 2023.

\bibitem{le2023voicebox}
Matthew Le, Apoorv Vyas, Bowen Shi, Brian Karrer, Leda Sari, Rashel Moritz,
  Mary Williamson, Vimal Manohar, Yossi Adi, Jay Mahadeokar, et~al.,
\newblock ``Voicebox: Text-guided multilingual universal speech generation at
  scale,''
\newblock {\em arXiv preprint arXiv:2306.15687}, 2023.

\bibitem{baevski2020wav2vec}
Alexei Baevski, Yuhao Zhou, Abdelrahman Mohamed, and Michael Auli,
\newblock ``wav2vec 2.0: A framework for self-supervised learning of speech
  representations,''
\newblock {\em Advances in neural information processing systems}, 2020.

\bibitem{Hsu2021HuBERTSS}
Wei-Ning Hsu, Benjamin Bolte, Yao-Hung~Hubert Tsai, Kushal Lakhotia, Ruslan
  Salakhutdinov, and Abdelrahman Mohamed,
\newblock ``Hubert: Self-supervised speech representation learning by masked
  prediction of hidden units,''
\newblock {\em IEEE/ACM Transactions on Audio, Speech, and Language
  Processing}, vol. 29, pp. 3451--3460, 2021.

\bibitem{Defossez2022HighFN}
Alexandre D{\'e}fossez, Jade Copet, Gabriel Synnaeve, and Yossi Adi,
\newblock ``High fidelity neural audio compression,''
\newblock {\em ArXiv}, vol. abs/2210.13438, 2022.

\bibitem{Zeghidour2022SoundStreamAE}
Neil Zeghidour, Alejandro Luebs, Ahmed Omran, Jan Skoglund, and Marco
  Tagliasacchi,
\newblock ``Soundstream: An end-to-end neural audio codec,''
\newblock {\em IEEE/ACM Transactions on Audio, Speech, and Language
  Processing}, vol. 30, pp. 495--507, 2022.

\bibitem{rombach2022high}
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj{\"o}rn
  Ommer,
\newblock ``High-resolution image synthesis with latent diffusion models,''
\newblock in {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, 2022, pp. 10684--10695.

\bibitem{zeghidour2021soundstream}
Neil Zeghidour, Alejandro Luebs, Ahmed Omran, Jan Skoglund, and Marco
  Tagliasacchi,
\newblock ``Soundstream: An end-to-end neural audio codec,''
\newblock {\em IEEE/ACM Transactions on Audio, Speech, and Language
  Processing}, vol. 30, pp. 495--507, 2021.

\bibitem{hsu2021hubert}
Wei-Ning Hsu, Benjamin Bolte, Yao-Hung~Hubert Tsai, Kushal Lakhotia, Ruslan
  Salakhutdinov, and Abdelrahman Mohamed,
\newblock ``Hubert: Self-supervised speech representation learning by masked
  prediction of hidden units,''
\newblock {\em IEEE/ACM Transactions on Audio, Speech, and Language
  Processing}, vol. 29, pp. 3451--3460, 2021.

\bibitem{radford2023robust}
Alec Radford, Jong~Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey, and
  Ilya Sutskever,
\newblock ``Robust speech recognition via large-scale weak supervision,''
\newblock in {\em International Conference on Machine Learning}. PMLR, 2023,
  pp. 28492--28518.

\bibitem{qiang2023improving}
Chunyu Qiang, Peng Yang, Hao Che, Ying Zhang, Xiaorui Wang, and Zhongyuan Wang,
\newblock ``Improving prosody for cross-speaker style transfer by
  semi-supervised style extractor and hierarchical modeling in speech
  synthesis,''
\newblock in {\em ICASSP 2023-2023 IEEE International Conference on Acoustics,
  Speech and Signal Processing (ICASSP)}. IEEE, 2023, pp. 1--5.

\bibitem{hu2018squeeze}
Jie Hu, Li~Shen, and Gang Sun,
\newblock ``Squeeze-and-excitation networks,''
\newblock in {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, 2018, pp. 7132--7141.

\bibitem{ho2020denoising}
Jonathan Ho, Ajay Jain, and Pieter Abbeel,
\newblock ``Denoising diffusion probabilistic models,''
\newblock {\em Advances in neural information processing systems}, vol. 33, pp.
  6840--6851, 2020.

\bibitem{kong2020diffwave}
Zhifeng Kong, Wei Ping, Jiaji Huang, Kexin Zhao, and Bryan Catanzaro,
\newblock ``Diffwave: A versatile diffusion model for audio synthesis,''
\newblock {\em arXiv preprint arXiv:2009.09761}, 2020.

\bibitem{oord2016wavenet}
Aaron van~den Oord, Sander Dieleman, Heiga Zen, Karen Simonyan, Oriol Vinyals,
  Alex Graves, Nal Kalchbrenner, Andrew Senior, and Koray Kavukcuoglu,
\newblock ``Wavenet: A generative model for raw audio,''
\newblock {\em arXiv preprint arXiv:1609.03499}, 2016.

\bibitem{shi2020aishell}
Yao Shi, Hui Bu, Xin Xu, Shaoji Zhang, and Ming Li,
\newblock ``Aishell-3: A multi-speaker mandarin tts corpus and the baselines,''
\newblock {\em arXiv preprint arXiv:2010.11567}, 2020.

\bibitem{qiang2022style}
Chunyu Qiang, Peng Yang, Hao Che, Xiaorui Wang, and Zhongyuan Wang,
\newblock ``Style-label-free: Cross-speaker style transfer by quantized vae and
  speaker-wise normalization in speech synthesis,''
\newblock in {\em 2022 13th International Symposium on Chinese Spoken Language
  Processing (ISCSLP)}, 2022, pp. 61--65.

\bibitem{qiang2022back}
Chunyu Qiang, Peng Yang, Hao Che, Jinba Xiao, Xiaorui Wang, and Zhongyuan Wang,
\newblock ``Back-translation-style data augmentation for mandarin chinese
  polyphone disambiguation,''
\newblock in {\em 2022 Asia-Pacific Signal and Information Processing
  Association Annual Summit and Conference (APSIPA ASC)}. IEEE, 2022, pp.
  1915--1919.

\end{thebibliography}
