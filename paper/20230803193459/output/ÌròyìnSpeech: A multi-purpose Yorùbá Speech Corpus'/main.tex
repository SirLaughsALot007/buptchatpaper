% Template for Blind ASRU-2023 paper; to be used with:
%          spconf.sty  - ICASSP/ICIP LaTeX style file, and
%          IEEEbib.bst - IEEE bibliography style file.
% --------------------------------------------------------------------------
\documentclass{article}
\usepackage{spconf,amsmath,graphicx}
\usepackage{multicol, multirow}
\usepackage{booktabs}% http://ctan.org/pkg/booktabs
\usepackage{color}
\usepackage{comment}
\usepackage{numprint}
\usepackage{hyperref}


% Example definitions.
% --------------------
\def\x{{\mathbf x}}
\def\L{{\cal L}}
\newcommand{\Yoruba}{Yor\`{u}b\'{a} }
\newcommand{\yoruba}{Yor\`{u}b\'{a} \ }
\newcommand{\YORUBA}{YOR\`{U}B\'{A} \ }
\newcommand{\iroyin}{\`{I}r\`{o}y\`{i}nSpeech}
\newcommand{\iroro}[1]{\textcolor{blue}{#1}}
% \newcommand{\david}[1]{\textcolor{red}{#1}}

% Title.
% ------
\title{\`{I}r\`{o}y\`{i}nSpeech: A multi-purpose Yor\`{u}b\'{a} Speech Corpus}
%
% Single address.
% ---------------
\name{Tol\'{u}l\d{o}p\d{\'{e}} \'{O}g\'{u}nr\d{\`{e}}m\'{i} $^{1}$, K\d{\'{o}}l\'{a} T\'{u}b\d{\`{o}}s\'{u}n$^{2}$,  Anuoluwapo Aremu$^{2}$, Iroro Orife$^{3}$, David Ifeoluwa Adelani$^{4}$}
\address{$^{1}$Stanford University, $^{2}$\Yoruba Names, $^{3}$Niger-Volta LTI, $^{4}$University College London}
%
% For example:
% ------------
%\address{School\\
%	Department\\
%	Address}
%
% Two addresses (uncomment and modify for two-address case).
% ----------------------------------------------------------
%\twoauthors
%  {A. Author-one, B. Author-two\sthanks{Thanks to XYZ agency for funding.}}
%	{School A-B\\
%	Department A-B\\
%	Address A-B}
%  {C. Author-three, D. Author-four\sthanks{The fourth author performed the work
%	while at ...}}
%	{School C-D\\
%	Department C-D\\
%	Address C-D}
%

 
\begin{document}
%\ninept
%
\maketitle
 
\section{Introduction}
\label{sec:intro}

% diacritics were in text - why?


We introduce the \iroyin \ corpus---a new dataset influenced by a desire to increase the amount of high quality, freely available, contemporary \Yoruba{} speech. We release a multi-purpose dataset that can be used for both TTS and ASR tasks. We curated text sentences from the news and creative writing domains under an open license i.e., CC-BY-4.0 and had multiple speakers record each sentence.  We provide \numprint{5000} of our utterances to the Common Voice \cite{commonvoice} platform to crowdsource transcriptions online. The dataset has 38.5 hours of data in total, recorded by 80 volunteers.


\section{The Yor\`{u}b\'{a} Language}
 The \Yoruba  language is native to South-western Nigeria, Republic of Benin, and Republic of Togo. It is one of the national languages of Nigeria also spoken in other countries like Ghana, CÃ´te d'Ivoire, Sierra Leone, Cuba and Brazil. The language belongs to the Niger-Congo family in the Volta-Niger sub-group, and is spoken by over 40 million native speakers~\cite{Ethnologue2019}, making it one of the most widely spoken African languages. 
 
 \yoruba has 25 letters without the Latin characters  (c, q, v, x and z) and with additional characters ({\d e}, gb, {\d s} , {\d o}). 
 There are 18 consonants, 
 seven oral vowels  (a, e, {\d e}, i, o, {\d o}, u), five nasal vowels, 
 (an, {\d e}n, in, 
 {\d o}n, un) and syllabic nasals 
({\`{m}}, {\'{m}}, {\`{n}}, {\'{n}}). \yoruba is a tonal language with three tones: low, middle and high. These tones are represented by the grave (``\textbackslash
''), optional macron (``$-$'') and acute (``/'') accents respectively.  These tones are applied on vowels and syllabic nasals, but the mid tone is usually ignored in writings. The tonal marks are important for correct pronunciation and lexical disambiguation. 

\section{The \`{I}r\`{o}y\`{i}nSpeech Corpus}
\label{sec:corp-creation}
\subsection{Preparation of text sentences}
Our goal was to combine news data and fictional texts to create a multi-purpose modern speech dataset, as other \yoruba datasets used utterances from religious texts or biblical data~\cite{gutkin_49562,meyer22c_interspeech}. The corpus texts were obtained from %thousands of news %headlines 
the news article domain of the MENYO-20k dataset \cite{adelani-etal-2021-effect} (an open-sourced multi-domain English-\yoruba machine translation corpus) with a non-restrictive license (i.e. CC-BY-4.0) and the \yoruba portion of the MasakhaNER 2.0 dataset~\cite{adelani-etal-2022-masakhaner} (i.e MasakhaNER-YOR) based on Asejere newspaper\footnote{\url{https://www.asejere.net/}}. The primary sources of the MENYO-20k dataset are the Voice of Nigeria newspaper\footnote{\url{https://yoruba.von.gov.ng/}} (a Nigerian government newspaper that publishes in seven Nigerian or regional languages---Arabic, English, French, Fulani, Hausa, Igbo, and \Yoruba) and the Global Voices newspaper\footnote{\url{https://yo.globalvoices.org/}}(an international, multilingual community of writers, translators, and human rights activists contributing articles in their native language). We restrict our selection of news articles to these published datasets for two reasons (1) they have a non-restrictive license, and  (2) the \yoruba sentences have been further verified for quality issues, for example missing diacritics in the original crawled Asejere and Voice of Nigeria articles. Overall, we obtained 3,048 sentences from Voice of Nigeria, 2,932 sentences from Global Voices, and 5,135 sentences from Asejere. In total, this gives us 11,115 sentences.


In order to obtain more sentences to reach our goal of 50 hours of speech, we added some sentences extracted and modified from unpublished short stories previously translated into \Yoruba{}\footnote{Short stories translated by K\d{\'{o}}l\'{a} T\'{u}b\d{\`{o}}s\'{u}n}. These texts were selected to broaden the domain of the vocabulary used in the dataset. In addition, we divided long sentences from the MENYO-20k and MasakhaNER-YOR into smaller utterances, and asked volunteers to manually generate new utterances with similar story or context as the original seed sentences. They also cross-checked the utterances for errors. In total, we had to manually generate about 8,000 sentences.
%In addition, some sentences were extracted and modified from unpublished short stories previously translated into \Yoruba{}. These texts were selected to broaden the domain of the vocabulary used in the dataset. Others were manually generated by volunteers based on the Global Voices headlines and cross-checked for errors. 
% what was of the process of manually generating the lines?
We then cleaned up the data to create a final script. To ensure the sentences were high-quality, we verified that diacritics were properly applied on each word and revised offensive or divisive religious terms within the text to reflect a neutral tone. Next, we modified the text for clarity and length to facilitate pronunciation, and localized non-Yor\`{u}b\'{a} words into \Yoruba{} (e.g names of places; Kaduna to \d{\`{O}}y\d{\'{o}}, Zamfara to O\`{n}d\'{o}, United States to \`{I}l\'{u} \d{O}ba, Buhari to B\`{u}h\'{a}r\'{i}, Kenya to K\d{\'{e}}\'{n}y\`{a}, etc).



\subsection{Recording of text sentences}
% make sure commonvoice is explained somewhere here 
\subsubsection{Corpus partitions}
Our text preparation yielded a total of %\numprint{27300} 
\numprint{20000} sentences which was used for the entire recording for both ASR and TTS. %were divided as follows for recording. %\numprint{5460} 
\numprint{6000} lines were recorded by two single speakers (one male, one female) in the age group of 25-30, yielding 5 hours of speech which we envision for TTS tasks. %\numprint{2730} 
\numprint{5000} lines were allocated for the Common Voice crowdsourced platform, which has yielded 6 hours of speech. Finally, we recorded in-house all the \numprint{20000} lines, or some 26 hours for ASR. %, which we intend for ASR, 
They were recorded by eighty different volunteers, each recording 250 lines during one-hour studio sessions. 

\begin{table}[h]
    \centering
    \begin{tabular}{crr}
    \toprule
     & No. of hours & No. of sentences \\
     \midrule
     TTS & 6h 36m & \numprint{6000}* \\
     In-house ASR  & 25h 55m & \numprint{20000} \\
     Common Voice ASR  & 6h 00m & \numprint{5000}* \\
     \midrule
    Total & 38h 32m & \numprint{20000} \\
    \bottomrule
    \end{tabular}
    \caption{A summary of dataset statistics. The utterances used for TTS recording and for CommonVoice are subsets of the ASR utterances.}
    \label{tab:dataset_stats}
\end{table}

%\subsubsection{The volunteers}
All volunteers were speakers of standard North West \Yoruba{}~\footnote{\url{http://www.africa.uga.edu/Yoruba/yorubabout.html}}, were screened for dialect uniformity, and ranged in age from 18 to 69 years. The initial \numprint{6000} lines single speaker (TTS) partition had one male and one female volunteer, while the \numprint{20000} lines multi-speaker (ASR) partition had 80 volunteers, 37 male and 43 female. The studio volunteers were provided with a token gift each as thank you for their time.


\subsubsection{Recording}
To create an acoustically suitable environment for recording, we obtained a portable vocal booth. The recording equipment comprised an AT 2020+ USB microphone, USB cables, and a 2022 M1-Series Macbook Pro.

The first five hours of audio were recorded with Audacity, a free, open-source digital audio editor and recording application. To divide each of these hour-long recordings into a short file for each sentence required many more additional hours of manual post-editing work. To solve this problem, the team developed a custom application for creating speech corpora, dubbed \textit{\Yoruba{}Voice SpeechRecorder}.

The tool works by reading a prepared text file, usually with 250 sentences and displays each line of text to be read in order. The app also provides transport controls to enable recording, playback and file-management or deletion, in the case of multiple takes. Finally, the tool saves individual audio files for each sentence to the hard-drive as well as a metadata index, which can be used programmatically to prepare training examples. Over 60\% of all lines recorded in total were recorded using the SpeechRecorder app.


\begin{table}[t]
    \centering
    \resizebox{\columnwidth}{!}{%
    \begin{tabular}{crr}
    \toprule
     & No. of hours & No. of sentences \\
     \midrule
     ML-SUPERB Train (1h) & 1h & 793 \\
    ML-SUPERB Train (10 mins) & 10m & 137 \\
    ML-SUPERB Dev  & 10m & 143 \\
     ML-SUPERB Test  & 10m & 131 \\
     \midrule
    Total & 1h 30m & 1204 \\
    \bottomrule
    \end{tabular}
    }
    \caption{A summary of ML-SUPERB dataset subset.}
    \label{tab:dataset_stats_ml}
\end{table}


\subsubsection{Post-production}
We had four forms of post-processing. Where possible, recordings that had issues that could be fixed manually, were repaired by removing simple clicks and disfluenices. 

In situations where the recording did not correspond with the text but the utterance remained grammatical, we did not rerecord the utterances but edited the text sentences instead. One example is the possessive extender morpheme vowel e.g. ``Il\'{e} wa'' (our house) is pronounced as ``Il\'{e} e wa'' â where the extra âeâ extends from the original root noun to show a self-referential towards the root noun.

We also fixed tone marking, spelling, or semantic mismatches. Words like ``n\'{i} il\'{e}'' (into the house) or ``s\'{i} ib\d{\`{e}}'' (to there) are often contracted to ``n\'{i}l\'{e}'' and ``s\'{i}b\d{\'{e}}'' respectively in spoken \Yoruba{} and are amended in the utterance accordingly. Tone pronunciation mistakes resulting in a change in the word such as ``il\'{e}'' (house) to ``il\d{\`{e}}'' (land) also result in utterances being amended. 



If audio files had a variety of issues that rendered them unusable we re-recorded them, usually by a different person of the same gender (thus different speaker ID). Some of the issues include:
\begin{itemize}
    \item Disfluenices: hesitations, stammers, clicks, sniffs, etc.
    \item External noises: paper rustling, microphone touching, intrusive voices, electronic notification beeps, etc
    \item Audio fidelity: low or uneven audio levels, clipping or distortion, or otherwise unintelligible words
    \item Incorrect dictation which could not be fixed by changing the script
\end{itemize}
% we rerecodred x hours 







\subsection{Dataset summary}
The resulting audio ended up at 38 hours and 20 minutes in total. We prepared 1hr 30 minutes out of the 36 hours for the ML-SUPERB new language track challenge\footnote{\url{https://mlsuperb.netlify.app/}}. ML-SUPERB stands for \textbf{M}ulti\textbf{L}ingual \textbf{S}peech processing \textbf{U}niversal \textbf{PER}formance Benchmark, a leaderboard to benchmark the performance of Self-Supervised Learning (SSL) models on over 100 languages in various speech processing tasks. The submitted data to ML-SUPERB is in Table \ref{tab:dataset_stats_ml}.

\section{Acknowledgement}
This work was carried out with support from Imminent Translated, whose 2022 funding helped support the project. Special thanks to Mr. Bode Adedeji and Miss Aguobi Nkechinyere Faith of the Department of Linguistics, University of Lagos, for permission to place our booth in their shared office while we did some of our recordings. Finally, we are grateful to Professor Christopher Manning and Professor Dan Jurafsky for their useful feedback on the draft. % , and to Imminent Translated, whose 2022 funding helped support the project"
%Mr. Bode Adedeji and Miss Aguobi Nkechinyere Faith of the dept. of linguistics, university of Lagos for the use

% References should be produced using the bibtex program from suitable
% BiBTeX files (here: strings, refs, manuals). The IEEEbib.bst bibliography
% style file from IEEE produces unsorted bibliography list.
% -------------------------------------------------------------------------
\bibliographystyle{IEEEbib}
\bibliography{strings,refs}



\end{document}
