\begin{thebibliography}{10}\itemsep=-1pt

\bibitem{faster_lio}
Chunge Bai, Tao Xiao, Yajie Chen, Haoqian Wang, Fang Zhang, and Xiang Gao.
\newblock Faster-lio: Lightweight tightly coupled lidar-inertial odometry using
  parallel sparse incremental voxels.
\newblock {\em IEEE Robotics and Automation Letters}, 7(2):4861--4868, 2022.

\bibitem{Burri25012016}
Michael Burri, Janosch Nikolic, Pascal Gohl, Thomas Schneider, Joern Rehder,
  Sammy Omari, Markus~W Achtelik, and Roland Siegwart.
\newblock The {EuRoC} micro aerial vehicle datasets.
\newblock {\em The International Journal of Robotics Research}, 2016.

\bibitem{orb-slam3}
Carlos Campos, Richard Elvira, Juan J.~Gómez Rodríguez, José~M. M.~Montiel,
  and Juan D.~Tardós.
\newblock Orb-slam3: An accurate open-source library for visual,
  visual–inertial, and multimap slam.
\newblock {\em IEEE Transactions on Robotics}, 37(6):1874--1890, 2021.

\bibitem{carlevaris2016university}
Nicholas Carlevaris-Bianco, Arash~K Ushani, and Ryan~M Eustice.
\newblock University of michigan north campus long-term vision and lidar
  dataset.
\newblock {\em The International Journal of Robotics Research},
  35(9):1023--1035, 2016.

\bibitem{https://doi.org/10.48550/arxiv.2205.13135}
Yun Chang, Kamak Ebadi, Christopher~E. Denniston, Muhammad~Fadhil Ginting,
  Antoni Rosinol, Andrzej Reinke, Matteo Palieri, Jingnan Shi, Arghya
  Chatterjee, Benjamin Morrell, Ali-akbar Agha-mohammadi, and Luca Carlone.
\newblock Lamp 2.0: A robust multi-robot slam system for operation in
  challenging large-scale underground environments, 2022.

\bibitem{Delmerico19icra}
Jeffrey Delmerico, Titus Cieslewski, Henri Rebecq, Matthias Faessler, and
  Davide Scaramuzza.
\newblock Are we ready for autonomous drone racing? the {UZH-FPV} drone racing
  dataset.
\newblock In {\em {IEEE} Int. Conf. Robot. Autom. ({ICRA})}, 2019.

\bibitem{air_museum}
Rodolphe Dubois, Alexandre Eudes, and Vincent Frémont.
\newblock Airmuseum: a heterogeneous multi-robot dataset for stereo-visual and
  inertial simultaneous localization and mapping.
\newblock In {\em 2020 IEEE International Conference on Multisensor Fusion and
  Integration for Intelligent Systems (MFI)}, pages 166--172, 2020.

\bibitem{4404126}
Naser El-Sheimy, Haiying Hou, and Xiaoji Niu.
\newblock Analysis and modeling of inertial sensors using allan variance.
\newblock {\em IEEE Transactions on Instrumentation and Measurement},
  57(1):140--149, 2008.

\bibitem{gaidon2016virtual}
Adrien Gaidon, Qiao Wang, Yohann Cabon, and Eleonora Vig.
\newblock Virtual worlds as proxy for multi-object tracking analysis.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 4340--4349, 2016.

\bibitem{geiger2013vision}
Andreas Geiger, Philip Lenz, Christoph Stiller, and Raquel Urtasun.
\newblock Vision meets robotics: The kitti dataset.
\newblock {\em The International Journal of Robotics Research},
  32(11):1231--1237, 2013.

\bibitem{Geiger2012CVPR}
Andreas Geiger, Philip Lenz, and Raquel Urtasun.
\newblock Are we ready for autonomous driving? {T}he {KITTI} {V}ision
  {B}enchmark {S}uite.
\newblock In {\em Conference on Computer Vision and Pattern Recognition
  (CVPR)}, 2012.

\bibitem{helmberger2022hilti}
Michael Helmberger, Kristian Morin, Beda Berner, Nitish Kumar, Giovanni Cioffi,
  and Davide Scaramuzza.
\newblock The hilti slam challenge dataset.
\newblock {\em IEEE Robotics and Automation Letters}, 7(3):7518--7525, 2022.

\bibitem{lajoie2022}
P.~Y. Lajoie, B. Ramtoula, F. Wu, and G. Beltrame.
\newblock Towards collaborative simultaneous localization and mapping: A survey
  of the current research landscape.
\newblock {\em Field Robotics}, 2:971--1000, 2022.

\bibitem{utias}
Keith~YK Leung, Yoni Halpern, Timothy~D Barfoot, and Hugh~HT Liu.
\newblock The utias multi-robot cooperative localization and mapping dataset.
\newblock {\em The International Journal of Robotics Research}, 30(8):969--974,
  2011.

\bibitem{clins}
Jiajun Lv, Kewei Hu, Jinhong Xu, Yong Liu, Xiushui Ma, and Xingxing Zuo.
\newblock {CLINS:} continuous-time trajectory estimation for lidar-inertial
  system.
\newblock {\em CoRR}, abs/2109.04687, 2021.

\bibitem{maddern20171}
Will Maddern, Geoffrey Pascoe, Chris Linegar, and Paul Newman.
\newblock 1 year, 1000 km: The oxford robotcar dataset.
\newblock {\em The International Journal of Robotics Research}, 36(1):3--15,
  2017.

\bibitem{pfrommer2017penncosyvio}
Bernd Pfrommer, Nitin Sanket, Kostas Daniilidis, and Jonas Cleveland.
\newblock Penncosyvio: A challenging visual inertial odometry benchmark.
\newblock In {\em 2017 IEEE International Conference on Robotics and Automation
  (ICRA)}, pages 3847--3854. IEEE, 2017.

\bibitem{rosario}
Taih{\'u} Pire, Mart{\'i}n Mujica, Javier Civera, and Ernesto Kofman.
\newblock The rosario dataset: Multisensor data for localization and mapping in
  agricultural environments.
\newblock {\em The International Journal of Robotics Research}, 38(6):633--641,
  2019.

\bibitem{vins-mono}
Tong Qin, Peiliang Li, and Shaojie Shen.
\newblock Vins-mono: A robust and versatile monocular visual-inertial state
  estimator.
\newblock {\em IEEE Transactions on Robotics}, 34(4):1004--1020, 2018.

\bibitem{9220149}
Jorge~Peña Queralta, Jussi Taipalmaa, Bilge Can~Pullinen, Victor~Kathan
  Sarker, Tuan Nguyen~Gia, Hannu Tenhunen, Moncef Gabbouj, Jenni Raitoharju,
  and Tomi Westerlund.
\newblock Collaborative multi-robot search and rescue: Planning, coordination,
  perception, and active vision.
\newblock {\em IEEE Access}, 8:191617--191643, 2020.

\bibitem{ramezani2020newer}
Milad Ramezani, Yiduo Wang, Marco Camurri, David Wisth, Matias Mattamala, and
  Maurice Fallon.
\newblock The newer college dataset: Handheld lidar, inertial and vision with
  ground truth.
\newblock In {\em 2020 IEEE/RSJ International Conference on Intelligent Robots
  and Systems (IROS)}, pages 4353--4360. IEEE, 2020.

\bibitem{schubert2018tum}
David Schubert, Thore Goll, Nikolaus Demmel, Vladyslav Usenko, J{\"o}rg
  St{\"u}ckler, and Daniel Cremers.
\newblock The tum vi benchmark for evaluating visual-inertial odometry.
\newblock In {\em 2018 IEEE/RSJ International Conference on Intelligent Robots
  and Systems (IROS)}, pages 1680--1687. IEEE, 2018.

\bibitem{segal2009generalized}
Aleksandr Segal, Dirk Haehnel, and Sebastian Thrun.
\newblock Generalized-icp.
\newblock In {\em Robotics: science and systems}, volume~2, page 435. Seattle,
  WA, 2009.

\bibitem{liosam2020shan}
Tixiao Shan, Brendan Englot, Drew Meyers, Wei Wang, Carlo Ratti, and Rus
  Daniela.
\newblock Lio-sam: Tightly-coupled lidar inertial odometry via smoothing and
  mapping.
\newblock In {\em IEEE/RSJ International Conference on Intelligent Robots and
  Systems (IROS)}, pages 5135--5142. IEEE, 2020.

\bibitem{tartanair2020iros}
Wenshan Wang, Delong Zhu, Xiangwei Wang, Yaoyu Hu, Yuheng Qiu, Chen Wang, Yafei
  Hu, Ashish Kapoor, and Sebastian Scherer.
\newblock Tartanair: A dataset to push the limits of visual {SLAM}.
\newblock In {\em 2020 IEEE/RSJ International Conference on Intelligent Robots
  and Systems (IROS)}, 2020.

\bibitem{fastlio}
Wei Xu, Yixi Cai, Dongjiao He, Jiarong Lin, and Fu Zhang.
\newblock {FAST-LIO2:} fast direct lidar-inertial odometry.
\newblock {\em IEEE Transactions on Robotics}, abs/2107.06829, 2022.

\bibitem{aloam}
Ji Zhang and Sanjiv Singh.
\newblock Loam : Lidar odometry and mapping in real-time.
\newblock {\em Robotics: Science and Systems Conference (RSS)}, pages 109--111,
  01 2014.

\bibitem{zhang2021multi}
Lintong Zhang, Marco Camurri, and Maurice Fallon.
\newblock Multi-camera lidar inertial extension to the newer college dataset.
\newblock {\em arXiv preprint arXiv:2112.08854}, 2021.

\bibitem{zhao2021super}
Shibo Zhao, Hengrui Zhang, Peng Wang, Lucas Nogueira, and Sebastian Scherer.
\newblock Super odometry: Imu-centric lidar-visual-inertial estimator for
  challenging environments.
\newblock In {\em 2021 IEEE/RSJ International Conference on Intelligent Robots
  and Systems (IROS)}, pages 8729--8736. IEEE, 2021.

\bibitem{zuniga2020vi}
David Zu{\~n}iga-No{\"e}l, Alberto Jaenal, Ruben Gomez-Ojeda, and Javier
  Gonzalez-Jimenez.
\newblock The uma-vi dataset: Visual--inertial odometry in low-textured and
  dynamic illumination environments.
\newblock {\em The International Journal of Robotics Research},
  39(9):1052--1060, 2020.

\end{thebibliography}
