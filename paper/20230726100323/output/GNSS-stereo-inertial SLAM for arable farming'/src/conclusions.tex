This work presents a GNSS-stereo-inertial SLAM framework that fuses in a tightly-coupled manner the information from a stereo camera, an IMU and a conventional GNSS sensor. In order to report the most competitive results, we implement our GNSS factor on top of the ORB-SLAM3 framework, the top performer in the evaluation of \cite{cremona2022evaluation}. As we are motivated by long-term autonomous navigation in arable farms, we present results in the Rosario Dataset and in-house sequences from an agricultural robot. Very importantly, several works in the literature evaluate GNSS-stereo-inertial SLAM methods by emulating conventional GNSS measurements while we use a real sensor, so we are the first ones in reporting results in realistic conditions in agricultural scenes.

Our results show that there is a consistent gain in accuracy if GNSS measurements are tightly fused with visual and inertial ones in the local mapping optimization of a SLAM system. Very importantly, not only the localization errors are reduced but also their variance between runs, indicating a looser dependence from the visual features used.

As an additional contribution of this work, we release our implementation for the benefit of the agricultural robotics community.

% As a result, in both cases an improvement in pose estimation was found. The implementation of this system is released as open source, as a contribution to agricultural robotics research.

%As future work, the incorporation of a magnetometer would allow the rotation between the world frame and the global frame $\rotationCoord{\coordIndex{\firstGPSCoordSystem}{0}}{\worldCoordSystem}$ to be calculated more accurately. 