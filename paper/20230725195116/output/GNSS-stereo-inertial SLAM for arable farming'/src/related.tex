Sensor fusion methods can be broadly divided into two groups, \emph{loosely-coupled} and \emph{tightly-coupled}. Loosely-coupled methods are those that omit correlations between measurements from different sensors. This simplifies the fusion, as the estimation from each sensor can run separately and the estimates be fused afterwards. Most of these approaches are based on filters, such as the Extended Kalman Filter (EKF), that sequentially updates the system state integrating previous information. This is however suboptimal compared to tightly-coupled methods \cite{strasdat2012why}, which model the correlations between state variables and sensor measurements. In this last case, the measurements from all sensors are jointly integrated in the same optimization problem. As a drawback, tightly-coupled solutions generally have a higher computational cost than loosely-coupled ones. In the rest of the section, we refer the most related works to ours, from the loosely-coupled to the tightly-coupled ones.

\citet{weiss2012versatile} propose an EKF-based estimation method for Micro Air Vehicles (MAV). Its contribution is a modular loosely-coupled method that is capable of fusing visual, inertial and external positioning sensor (such as GPS or a laser telemetry tracking system) information. The results show that the proposed method allows state predictions to be made up to \SI{1}{\kilo\hertz} for MAV control tasks, being robust to low frequency measurements of \SI{1}{\hertz}, delays of up to \SI{500}{\milli\second} in the measurements and noise with standard deviations up to \SI{20}{\centi\meter}. \citet{shen2014multi} presents a similar loosely-coupled approach but using an Unscented Kalman Filter (UKF), in order to better address the non-linearities in the sensor models.  \citet{wei2011intelligent} use stereo cameras to estimate the motion of a ground robot, considering motions only in the horizontal plane, and using an EKF to fuse global GPS measurements in a loosely-coupled manner, reducing the drift. \citet{won2014selective,Won2014gnss} propose a selective integration method for GNSS, visual and inertial measurements to improve localization accuracy under GNSS-challenged environments. The authors introduced a new performance index to recognize poor environments based on the geometrical distribution of the satellites and the local image features. 

\citet{li2019tight} present a multi-state constraint Kalman filter (MSCKF) approach to fuse monocular, inertial and raw GNSS-RTK measurements. The MSCKF makes use of a measurement model that does not require to include the feature landmarks in the state vector of the EKF, improving the robustness and computational complexity of the system. \citet{salehi2017hybrid} use a mixture of tightly-coupled and loosely-coupled techniques for the fusion of visual and GPS measurements. An exhaustive optimization restricted to a temporal window of recent visual measurements is used, while measurements outside the window are marginalized by obtaining estimates of relative motion between poses. This allows to improve computational times, preventing the computational complexity to scale. \citet{yu2019gpsaided} present a GPS-assisted visual-inertial estimation framework for omnidirectional platforms. It extends VINS-MONO \cite{qin2018vins} to support multiple cameras, fuses visual and inertial information in a tightly-coupled manner, combined with a loosely-coupled approach to incorporate the measurements provided by GPS. Later, the same authors present GVINS \cite{cao2021gvins}, a framework based on non-linear optimization. GVINS tightly fuses GNSS raw measurements with visual and inertial information for state estimation. The GNSS pseudorange and Doppler shift measurements are modelled under a probabilistic factor graph framework along with visual and inertial constraints. The same approach is applied in \cite{liu2021optimization}.

\citet{lynen2013robust} present Multi-Sensor Fusion (MSF), a modular sensor fusion system based on an EKF filter where inertial information is used at the prediction step. The information coming from the different sensors is modeled in a general manner as relative and/or absolute pose estimates, thus allowing to fuse measurements coming from a large number of sensors using a loosely-coupled approach. The work places particular emphasis on modelling the temporal arrival of the measurements by applying a technique known as Stochastic Cloning able to address asynchronous sensor fusion. \citet{mascaro2018gomsf} present the Graph-Optimization based Multi-Sensor Fusion (GOMSF) framework which solves the fusion of pose estimates in different coordinate systems. Visual-inertial estimates from the MSF in local coordinates are merged with measurements in global coordinates from a GPS. %For this purpose, a fixed-size sliding window optimization is proposed, which considers a predefined number of poses and measurements. The resulting method shows significant accuracy improvements over using the MSF system alone.
%paper no muy bien redactado, no es claro: \citet{dong2022tightly}
% paper cuya revista no aparece rankeada \citet{li2021semi}

\citet{lee2020intermittent} present a GPS-VIO system that fuses visual-inertial data with intermittent GPS measurements is presented. The authors proposed a GPS-IMU online calibration approach for the time offset and extrinsics estimation. In \cite{boche2022dropout} a tightly coupled visual-inertial-GPS system is presented. The system is based on OKVIS2 \cite{leutenegger2022okvis2}. In the work a new global reference frame initialisation has been introduced that incorporates measurement uncertainties to decide whether the extrinsic transformation between the global and visual-inertial reference frame becomes observable.

In contrast to the previously mentioned works, this paper presents a tightly-coupled GNSS-stereo-inertial SLAM to tackle localization in agricultural environments. The proposed framework extends the Visual-Inertial SLAM system ORB-SLAM3 \cite{campos2021orbslam3} with GNSS measurements. We built on top of ORB-SLAM3 since it has a fair performance in agricultural environments \cite{cremona2022evaluation}. Our implementation is publicly released as open source to facilitate its use, extension and reproduction of the results by the robotics community.

% Moreover, it is important to remark that state-of-the-art GNSS-Visual-Inertial methods as \cite{cioffi2020tightly,bloesch2015robust} were evaluated with simulated GNSS measurement (adding isotropic Gaussian noise to ground-truth).