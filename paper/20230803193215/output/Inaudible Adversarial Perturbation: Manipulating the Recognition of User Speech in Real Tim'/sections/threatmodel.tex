%  !TEX root = ../main.tex
\subsection{Threat Model}\label{sec:threat_model}
\textbf{Attack Scenarios:}\label{attack_scenario}
We consider attacks in user-present scenarios where the user may notice unintended events of ASR services. Such scenarios involve two entities:\\
\underline{\textbf{Victim}:} The victim user is alert to any strange sounds (e.g., noise, music, pulses) within human auditory. The user can speak an arbitrary command to the smart speaker. Once the user notices attacks, he/she can speak a remedy command to the smart speaker.\\
\underline{\textbf{Adversary}:} The adversary prepares IAPs for specific intentions offline and alters user command in real time by delivering IAPs \ding{172}at a distance from the victim with an ultrasonic transmitter through the window, \ding{173}physically close with a handheld portable device, or \ding{174}with a preset off-the-shelf loudspeaker. The adversary's goals are providing wrong information to intelligent voice customer service, compromising VAs to execute malicious commands or be in denial-of-service mode, etc. The adversary can attack more covertly with two strategies: \textit{1) No-feedback Attack}: Prevent the user from hearing VA's vocal prompt by ``Mute volume and turn off the WiFi''. \textit{2) Man-in-the-middle Attack}: Once the user's intent is satisfied, the attack may be much less suspicious, i.e., while delivering the adversarial perturbation and alter user commands, adversaries can record the user commands and then replay it by traditional ultrasound-based attack means. 

\textbf{Attacker Capability:}
Distinct from the previous works~\cite{carlini2018audio,chen2020metamorph,yuan2018commandersong,qin2019imperceptible,chen2021fakebob,schonherr2018adversarial,li2023tuner} that require the user's speech samples in advance to craft adversarial perturbation, we assume the adversaries have no knowledge of what the user will speak during performing attacks.
In line with the widely adopted settings in prior works~\cite{yuan2018commandersong,carlini2018audio,chen2020metamorph,qin2019imperceptible,guo2022specpatch}, we assume the attackers have prior knowledge of the target ASR model for obtaining the gradient information during optimization.
The adversaries have access to the user's recording device, e.g., borrow a smartphone of the same brand, based on which the adversary can model the ultrasonic transformation, and then create the IAP in advance.
We assume adversaries have the flexibility to deploy the hidden ultrasonic transmitter nearly or at a distance, and the recording device is in its line of sight. Additionally, adversaries can also utilize stealthy portable devices and off-the-shelf loudspeakers in everyday-life scenarios to deliver \alias.
