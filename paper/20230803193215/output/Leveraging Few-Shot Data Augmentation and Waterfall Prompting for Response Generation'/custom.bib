% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").
@article{midas-2019,
  author       = {Dian Yu and
                  Zhou Yu},
  title        = {{MIDAS:} {A} Dialog Act Annotation Scheme for Open Domain Human Machine
                  Spoken Conversations},
  journal      = {CoRR},
  volume       = {abs/1908.10023},
  year         = {2019},
  url          = {http://arxiv.org/abs/1908.10023},
  eprinttype    = {arXiv},
  eprint       = {1908.10023},
  timestamp    = {Thu, 30 Dec 2021 09:02:58 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1908-10023.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{lee2021neural,
  title={Neural data augmentation via example extrapolation},
  author={Lee, Kenton and Guu, Kelvin and He, Luheng and Dozat, Tim and Chung, Hyung Won},
  journal={arXiv preprint arXiv:2102.01335},
  year={2021}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@misc{sun2023recitationaugmented,
      title={Recitation-Augmented Language Models}, 
      author={Zhiqing Sun and Xuezhi Wang and Yi Tay and Yiming Yang and Denny Zhou},
      year={2023},
      eprint={2210.01296},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{wang2023selfconsistency,
      title={Self-Consistency Improves Chain of Thought Reasoning in Language Models}, 
      author={Xuezhi Wang and Jason Wei and Dale Schuurmans and Quoc Le and Ed Chi and Sharan Narang and Aakanksha Chowdhery and Denny Zhou},
      year={2023},
      eprint={2203.11171},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{singhal2023expertlevel,
      title={Towards Expert-Level Medical Question Answering with Large Language Models}, 
      author={Karan Singhal and Tao Tu and Juraj Gottweis and Rory Sayres and Ellery Wulczyn and Le Hou and Kevin Clark and Stephen Pfohl and Heather Cole-Lewis and Darlene Neal and Mike Schaekermann and Amy Wang and Mohamed Amin and Sami Lachgar and Philip Mansfield and Sushant Prakash and Bradley Green and Ewa Dominowska and Blaise Aguera y Arcas and Nenad Tomasev and Yun Liu and Renee Wong and Christopher Semturs and S. Sara Mahdavi and Joelle Barral and Dale Webster and Greg S. Corrado and Yossi Matias and Shekoofeh Azizi and Alan Karthikesalingam and Vivek Natarajan},
      year={2023},
      eprint={2305.09617},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{Anaby-Tavor_etal_2020, 
    title={Do Not Have Enough Data? Deep Learning to the Rescue!}, 
    volume={34}, 
    url={https://ojs.aaai.org/index.php/AAAI/article/view/6233}, DOI={10.1609/aaai.v34i05.6233}, 
    abstractNote={&lt;p&gt;Based on recent advances in natural language modeling and those in text generation capabilities, we propose a novel data augmentation method for text classification tasks. We use a powerful pre-trained neural network model to artificially synthesize new labeled data for supervised learning. We mainly focus on cases with scarce labeled data. Our method, referred to as &lt;em&gt;language-model-based data augmentation (LAMBADA)&lt;/em&gt;, involves fine-tuning a state-of-the-art language generator to a specific task through an initial training phase on the existing (usually small) labeled data. Using the fine-tuned model and given a class label, new sentences for the class are generated. Our process then filters these new sentences by using a classifier trained on the original data. In a series of experiments, we show that LAMBADA improves classifiersâ€™ performance on a variety of datasets. Moreover, LAMBADA significantly improves upon the state-of-the-art techniques for data augmentation, specifically those applicable to text classification tasks with little data.&lt;/p&gt;}, 
    number={05}, 
    journal={Proceedings of the AAAI Conference on Artificial Intelligence}, 
    author={Anaby-Tavor, Ateret and Carmeli, Boaz and Goldbraich, Esther and Kantor, Amir and Kour, George and Shlomov, Segev and Tepper, Naama and Zwerdling, Naama}, 
    year={2020}, 
    month={Apr.}, 
    pages={7383-7390} }


@misc{bhaskar2023prompted,
      title={Prompted Opinion Summarization with GPT-3.5}, 
      author={Adithya Bhaskar and Alexander R. Fabbri and Greg Durrett},
      year={2023},
      eprint={2211.15914},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{pitis2023boosted,
  title={Boosted Prompt Ensembles for Large Language Models},
  author={Pitis, Silviu and Zhang, Michael R and Wang, Andrew and Ba, Jimmy},
  journal={arXiv preprint arXiv:2304.05970},
  year={2023}
}

@article{wang2022rationale,
  title={Rationale-augmented ensembles in language models},
  author={Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc and Chi, Ed and Zhou, Denny},
  journal={arXiv preprint arXiv:2207.00747},
  year={2022}
}

@article{wei2022chain,
  title={Chain of thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Chi, Ed and Le, Quoc and Zhou, Denny},
  journal={arXiv preprint arXiv:2201.11903},
  year={2022}
}

@inproceedings{thulkeDSTC2021,
  title = {{{Adapting Document-Grounded Dialog Systems}} to {{Spoken Conversations}} using {{Data Augmentation}} and a {{Noisy Channel Model}}},
  booktitle = {{{Workshop}} on {{DSTC10}}, {{AAAI}}},
  author = {Thulke, David and Daheim, Nico and Dugast, Christian and Ney, Hermann},
  year = {2022},
}

@article{chung2022scaling,
  title={Scaling instruction-finetuned language models},
  author={Chung, Hyung Won and Hou, Le and Longpre, Shayne and Zoph, Barret and Tay, Yi and Fedus, William and Li, Eric and Wang, Xuezhi and Dehghani, Mostafa and Brahma, Siddhartha and others},
  journal={arXiv preprint arXiv:2210.11416},
  year={2022}
}

@article{tian2021tod-da,
  title={TOD-DA: Towards Boosting the Robustness of Task-oriented Dialogue Modeling on Spoken Conversations},
  author={Tian, Xin and Huang, Xinxian and He, Dongfeng and Lin, Yingzhan and Bao, Siqi and He, Huang and Huang, Liankai and Ju, Qiang and Zhang, Xiyuan and Xie, Jian and Sun, Shuqi and Wang, Fan and Wu, Hua and Wang, Haifeng},
  journal={arXiv preprint arXiv:2112.12441},
  year={2021}
}

@article{kim2022knowledge,
  title={Knowledge-grounded task-oriented dialogue modeling on spoken conversations track at DSTC10},
  author={Kim, Seokhwan and Liu, Yang and Jin, Di and Papangelis, Alexandros and Hedayatnia, Behnam and Gopalakrishnan, Karthik and Hakkani-T{\"u}r, Dilek},
  year={2022}
}

@article{choshen2022start,
  title={Where to start? Analyzing the potential value of intermediate models},
  author={Choshen, Leshem and Venezian, Elad and Don-Yehia, Shachar and Slonim, Noam and Katz, Yoav},
  journal={arXiv preprint arXiv:2211.00107},
  year={2022}
}

@article{zhao2023others,
  title={" What do others think?": Task-Oriented Conversational Modeling with Subjective Knowledge},
  author={Zhao, Chao and Gella, Spandana and Kim, Seokhwan and Jin, Di and Hazarika, Devamanyu and Papangelis, Alexandros and Hedayatnia, Behnam and Namazifar, Mahdi and Liu, Yang and Hakkani-Tur, Dilek},
  journal={arXiv preprint arXiv:2305.12091},
  year={2023}
}

@inproceedings{gliwa2019samsum,
    title = "{SAMS}um Corpus: A Human-annotated Dialogue Dataset for Abstractive Summarization",
    author = "Gliwa, Bogdan  and
      Mochol, Iwona  and
      Biesek, Maciej  and
      Wawer, Aleksander",
    booktitle = "Proceedings of the 2nd Workshop on New Frontiers in Summarization",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-5409",
    doi = "10.18653/v1/D19-5409",
    pages = "70--79",
    abstract = "This paper introduces the SAMSum Corpus, a new dataset with abstractive dialogue summaries. We investigate the challenges it poses for automated summarization by testing several models and comparing their results with those obtained on a corpus of news articles. We show that model-generated summaries of dialogues achieve higher ROUGE scores than the model-generated summaries of news {--} in contrast with human evaluators{'} judgement. This suggests that a challenging task of abstractive dialogue summarization requires dedicated models and non-standard quality measures. To our knowledge, our study is the first attempt to introduce a high-quality chat-dialogues corpus, manually annotated with abstractive summarizations, which can be used by the research community for further studies.",
}

